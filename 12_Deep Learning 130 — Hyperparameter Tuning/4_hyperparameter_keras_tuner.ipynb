{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "4_hyperparameter_keras_tuner.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YonDraco/learn-pyimagesearch/blob/master/4_hyperparameter_keras_tuner.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kEYvcfHRB8dw"
      },
      "source": [
        "![pyimagesearch_university_logo.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4RpK9pawQzP"
      },
      "source": [
        "# Easy Hyperparameter Tuning with Keras Tuner and TensorFlow\n",
        "### by [PyImageSearch.com](http://www.pyimagesearch.com)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ntZ1AkXZIxY"
      },
      "source": [
        "## Welcome to **[PyImageSearch University](https://pyimg.co/university)** Jupyter Notebooks!\n",
        "\n",
        "This notebook is associated with the [Easy Hyperparameter Tuning with Keras Tuner and TensorFlow](https://www.pyimagesearch.com/2021/06/07/easy-hyperparameter-tuning-with-keras-tuner-and-tensorflow/) blog post published on 2021-06-07.\n",
        "\n",
        "Only the code for the blog post is here. Most codeblocks have a 1:1 relationship with what you find in the blog post with two exceptions: (1) Python classes are not separate files as they are typically organized with PyImageSearch projects, and (2) Command Line Argument parsing is replaced with an `args` dictionary that you can manipulate as needed.\n",
        "\n",
        "We recommend that you execute (press ▶️) the code block-by-block, as-is, before adjusting parameters and `args` inputs. Once you've verified that the code is working, you are welcome to hack with it and learn from manipulating inputs, settings, and parameters. For more information on using Jupyter and Colab, please refer to these resources:\n",
        "\n",
        "*   [Jupyter Notebook User Interface](https://jupyter-notebook.readthedocs.io/en/stable/notebook.html#notebook-user-interface)\n",
        "*   [Overview of Google Colaboratory Features](https://colab.research.google.com/notebooks/basic_features_overview.ipynb)\n",
        "\n",
        "As a reminder, these PyImageSearch University Jupyter Notebooks are not for sharing; please refer to the **Copyright** directly below and **Code License Agreement** in the last cell of this notebook. \n",
        "\n",
        "Happy hacking!\n",
        "\n",
        "*Adrian*\n",
        "\n",
        "<hr>\n",
        "\n",
        "***Copyright:*** *The contents of this Jupyter Notebook, unless otherwise indicated, are Copyright 2021 Adrian Rosebrock, PyimageSearch.com. All rights reserved. Content like this is made possible by the time invested by the authors. If you received this Jupyter Notebook and did not purchase it, please consider making future content possible by joining PyImageSearch University at https://pyimg.co/university today.*"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LY860Q9z8436"
      },
      "source": [
        "### Install the necessary packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w69SzOKK86rN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bf7378bb-0753-43a0-aefd-4eef99a1f95f"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "  Downloading keras_tuner-1.0.3-py3-none-any.whl (96 kB)\n",
            "\u001b[?25l\r\u001b[K     |███▍                            | 10 kB 24.7 MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 20 kB 30.2 MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 30 kB 29.6 MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 40 kB 21.0 MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 51 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 61 kB 9.5 MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 71 kB 7.7 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 81 kB 8.6 MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 92 kB 9.4 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 96 kB 1.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (21.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (5.5.0)\n",
            "Requirement already satisfied: tensorboard in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (2.6.0)\n",
            "Collecting kt-legacy\n",
            "  Downloading kt_legacy-1.0.4-py3-none-any.whl (9.6 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (1.0.18)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.8.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (0.7.5)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (4.8.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (57.4.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->keras-tuner) (5.0.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->keras-tuner) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->keras-tuner) (0.2.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect->ipython->keras-tuner) (0.7.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.39.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.6.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.8.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.37.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.3.4)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (3.17.3)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (0.12.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard->keras-tuner) (1.34.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.7.2)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (4.2.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard->keras-tuner) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard->keras-tuner) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard->keras-tuner) (3.1.1)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard->keras-tuner) (3.5.0)\n",
            "Installing collected packages: kt-legacy, keras-tuner\n",
            "Successfully installed keras-tuner-1.0.3 kt-legacy-1.0.4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NFhAzQB3aNMa"
      },
      "source": [
        "### Download the code zip file"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7y0LG1EuaRlB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c8024ceb-95ef-4abf-8833-e6a92c92dd2a"
      },
      "source": [
        "!wget https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/hyperparameter-keras-tuner/hyperparameter-keras-tuner.zip\n",
        "!unzip -qq hyperparameter-keras-tuner.zip\n",
        "%cd hyperparameter-keras-tuner"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-08-25 19:05:34--  https://pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com/hyperparameter-keras-tuner/hyperparameter-keras-tuner.zip\n",
            "Resolving pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)... 52.218.184.169\n",
            "Connecting to pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com (pyimagesearch-code-downloads.s3-us-west-2.amazonaws.com)|52.218.184.169|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 142561 (139K) [binary/octet-stream]\n",
            "Saving to: ‘hyperparameter-keras-tuner.zip’\n",
            "\n",
            "hyperparameter-kera 100%[===================>] 139.22K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2021-08-25 19:05:34 (3.19 MB/s) - ‘hyperparameter-keras-tuner.zip’ saved [142561/142561]\n",
            "\n",
            "/content/hyperparameter-keras-tuner\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SgTVT3HagGZ"
      },
      "source": [
        "## Blog Post Code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wcrOk6pURp50"
      },
      "source": [
        "### Import Packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJaCNlDDRz6d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed8bc35c-d109-4795-e3f5-22f0cffc4e6c"
      },
      "source": [
        "# set the matplotlib backend so figures can be saved in the background\n",
        "import matplotlib\n",
        "matplotlib.use(\"Agg\")\n",
        "\n",
        "# import the necessary package\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "from tensorflow.keras.layers import Activation\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras import backend as K\n",
        "from sklearn.metrics import classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import kerastuner as kt\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:21: DeprecationWarning: `import kerastuner` is deprecated, please use `import keras_tuner`.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lBrLwCtN5kqy"
      },
      "source": [
        "### Implementing our Config class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ab1zz-lQ9K3M"
      },
      "source": [
        "class Config:\n",
        "    # define the path to our output directory\n",
        "    OUTPUT_PATH = \"output\"\n",
        "\n",
        "    # initialize the input shape and number of classes\n",
        "    INPUT_SHAPE = (28, 28, 1)\n",
        "    NUM_CLASSES = 10\n",
        "\n",
        "    # define the total number of epochs to train, batch size, and the\n",
        "    # early stopping patience\n",
        "    EPOCHS = 50\n",
        "    BS = 32\n",
        "    EARLY_STOPPING_PATIENCE = 5\n",
        "\n",
        "# instantiate an object of the configuration class\n",
        "config = Config()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ql-F1dT99oqS"
      },
      "source": [
        "### Implementing our plotting helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QdV_hZvo9p09"
      },
      "source": [
        "def save_plot(H, path):\n",
        "\t# plot the training loss and accuracy\n",
        "\tplt.style.use(\"ggplot\")\n",
        "\tplt.figure()\n",
        "\tplt.plot(H.history[\"loss\"], label=\"train_loss\")\n",
        "\tplt.plot(H.history[\"val_loss\"], label=\"val_loss\")\n",
        "\tplt.plot(H.history[\"accuracy\"], label=\"train_acc\")\n",
        "\tplt.plot(H.history[\"val_accuracy\"], label=\"val_acc\")\n",
        "\tplt.title(\"Training Loss and Accuracy\")\n",
        "\tplt.xlabel(\"Epoch #\")\n",
        "\tplt.ylabel(\"Loss/Accuracy\")\n",
        "\tplt.legend()\n",
        "\tplt.savefig(path)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p1Qg4cNv96o8"
      },
      "source": [
        "### Creating our CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc9wiaGC-Cl6"
      },
      "source": [
        "def build_model(hp):\n",
        "\t# initialize the model along with the input shape and channel\n",
        "\t# dimension\n",
        "\tmodel = Sequential()\n",
        "\tinputShape = config.INPUT_SHAPE\n",
        "\tchanDim = -1\n",
        "\n",
        "\t# first CONV => RELU => POOL layer set\n",
        "\tmodel.add(Conv2D(\n",
        "\t\thp.Int(\"conv_1\", min_value=32, max_value=96, step=32),\n",
        "\t\t(3, 3), padding=\"same\", input_shape=inputShape))\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# second CONV => RELU => POOL layer set\n",
        "\tmodel.add(Conv2D(\n",
        "\t\thp.Int(\"conv_2\", min_value=64, max_value=128, step=32),\n",
        "\t\t(3, 3), padding=\"same\"))\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tmodel.add(BatchNormalization(axis=chanDim))\n",
        "\tmodel.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "\t# first (and only) set of FC => RELU layers\n",
        "\tmodel.add(Flatten())\n",
        "\tmodel.add(Dense(hp.Int(\"dense_units\", min_value=256,\n",
        "\t\tmax_value=768, step=256)))\n",
        "\tmodel.add(Activation(\"relu\"))\n",
        "\tmodel.add(BatchNormalization())\n",
        "\tmodel.add(Dropout(0.5))\n",
        "\n",
        "\t# softmax classifier\n",
        "\tmodel.add(Dense(config.NUM_CLASSES))\n",
        "\tmodel.add(Activation(\"softmax\"))\n",
        "\n",
        "\t# initialize the learning rate choices and optimizer\n",
        "\tlr = hp.Choice(\"learning_rate\",\n",
        "\t\tvalues=[1e-1, 1e-2, 1e-3])\n",
        "\topt = Adam(learning_rate=lr)\n",
        "\n",
        "\t# compile the model\n",
        "\tmodel.compile(optimizer=opt, loss=\"categorical_crossentropy\",\n",
        "\t\tmetrics=[\"accuracy\"])\n",
        "\n",
        "\t# return the model\n",
        "\treturn model"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jppw5-Bd56H-"
      },
      "source": [
        "### Implementing hyperparameter tuning with Keras Tuner"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "okM7Bpyeq8Kc"
      },
      "source": [
        "# # construct the argument parser and parse the arguments\n",
        "# ap = argparse.ArgumentParser()\n",
        "# ap.add_argument(\"-t\", \"--tuner\", required=True, type=str,\n",
        "# \tchoices=[\"hyperband\", \"random\", \"bayesian\"],\n",
        "# \thelp=\"type of hyperparameter tuner we'll be using\")\n",
        "# ap.add_argument(\"-p\", \"--plot\", required=True,\n",
        "# \thelp=\"path to output accuracy/loss plot\")\n",
        "# args = vars(ap.parse_args())\n",
        "\n",
        "# since we are using Jupyter Notebooks we can replace our argument\n",
        "# parsing code with *hard coded* arguments and values\n",
        "args = {\n",
        "\t\"tuner\": \"random\",\n",
        "\t\"plot\": \"output/random_plot.png\"\n",
        "}"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7o5QRa7-k0R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd8d434e-78c2-46eb-8a79-9fddf0e0c2f7"
      },
      "source": [
        "# load the Fashion MNIST dataset\n",
        "print(\"[INFO] loading Fashion MNIST...\")\n",
        "((trainX, trainY), (testX, testY)) = fashion_mnist.load_data()\n",
        "\n",
        "# add a channel dimension to the dataset\n",
        "trainX = trainX.reshape((trainX.shape[0], 28, 28, 1))\n",
        "testX = testX.reshape((testX.shape[0], 28, 28, 1))\n",
        "\n",
        "# scale data to the range of [0, 1]\n",
        "trainX = trainX.astype(\"float32\") / 255.0\n",
        "testX = testX.astype(\"float32\") / 255.0\n",
        "\n",
        "# one-hot encode the training and testing labels\n",
        "trainY = to_categorical(trainY, 10)\n",
        "testY = to_categorical(testY, 10)\n",
        "\n",
        "# initialize the label names\n",
        "labelNames = [\"top\", \"trouser\", \"pullover\", \"dress\", \"coat\",\n",
        "\t\"sandal\", \"shirt\", \"sneaker\", \"bag\", \"ankle boot\"]"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] loading Fashion MNIST...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88MljWTG-rS6"
      },
      "source": [
        "# initialize an early stopping callback to prevent the model from\n",
        "# overfitting/spending too much time training with minimal gains\n",
        "es = EarlyStopping(\n",
        "\tmonitor=\"val_loss\",\n",
        "\tpatience=config.EARLY_STOPPING_PATIENCE,\n",
        "\trestore_best_weights=True)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m1DYgCSb-ub-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b1f96653-4c45-4910-b41b-00c653eecefa"
      },
      "source": [
        "# check if we will be using the hyperband tuner\n",
        "if args[\"tuner\"] == \"hyperband\":\n",
        "\t# instantiate the hyperband tuner object\n",
        "\tprint(\"[INFO] instantiating a hyperband tuner object...\")\n",
        "\ttuner = kt.Hyperband(\n",
        "\t\tbuild_model,\n",
        "\t\tobjective=\"val_accuracy\",\n",
        "\t\tmax_epochs=config.EPOCHS,\n",
        "\t\tfactor=3,\n",
        "\t\tseed=42,\n",
        "\t\tdirectory=config.OUTPUT_PATH,\n",
        "\t\tproject_name=args[\"tuner\"])\n",
        "\n",
        "# check if we will be using the random search tuner\n",
        "elif args[\"tuner\"] == \"random\":\n",
        "\t# instantiate the random search tuner object\n",
        "\tprint(\"[INFO] instantiating a random search tuner object...\")\n",
        "\ttuner = kt.RandomSearch(\n",
        "\t\tbuild_model,\n",
        "\t\tobjective=\"val_accuracy\",\n",
        "\t\tmax_trials=10,\n",
        "\t\tseed=42,\n",
        "\t\tdirectory=config.OUTPUT_PATH,\n",
        "\t\tproject_name=args[\"tuner\"])\n",
        "\n",
        "# otherwise, we will be using the bayesian optimization tuner\n",
        "else:\n",
        "\t# instantiate the bayesian optimization tuner object\n",
        "\tprint(\"[INFO] instantiating a bayesian optimization tuner object...\")\n",
        "\ttuner = kt.BayesianOptimization(\n",
        "\t\tbuild_model,\n",
        "\t\tobjective=\"val_accuracy\",\n",
        "\t\tmax_trials=10,\n",
        "\t\tseed=42,\n",
        "\t\tdirectory=config.OUTPUT_PATH,\n",
        "\t\tproject_name=args[\"tuner\"])"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] instantiating a random search tuner object...\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcI4ORqF-8J7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "952560cd-56dd-4009-e4f4-019f7db2d613"
      },
      "source": [
        "# perform the hyperparameter search\n",
        "print(\"[INFO] performing hyperparameter search...\")\n",
        "tuner.search(\n",
        "\tx=trainX, y=trainY,\n",
        "\tvalidation_data=(testX, testY),\n",
        "\tbatch_size=config.BS,\n",
        "\tcallbacks=[es],\n",
        "\tepochs=config.EPOCHS\n",
        ")\n",
        "\n",
        "# grab the best hyperparameters\n",
        "bestHP = tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"[INFO] optimal number of filters in conv_1 layer: {}\".format(\n",
        "\tbestHP.get(\"conv_1\")))\n",
        "print(\"[INFO] optimal number of filters in conv_2 layer: {}\".format(\n",
        "\tbestHP.get(\"conv_2\")))\n",
        "print(\"[INFO] optimal number of units in dense layer: {}\".format(\n",
        "\tbestHP.get(\"dense_units\")))\n",
        "print(\"[INFO] optimal learning rate: {:.4f}\".format(\n",
        "\tbestHP.get(\"learning_rate\")))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 10 Complete [00h 01m 28s]\n",
            "val_accuracy: 0.8831999897956848\n",
            "\n",
            "Best val_accuracy So Far: 0.9258000254631042\n",
            "Total elapsed time: 00h 18m 04s\n",
            "INFO:tensorflow:Oracle triggered exit\n",
            "[INFO] optimal number of filters in conv_1 layer: 96\n",
            "[INFO] optimal number of filters in conv_2 layer: 64\n",
            "[INFO] optimal number of units in dense layer: 512\n",
            "[INFO] optimal learning rate: 0.0010\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9l13P1IP_ElZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45a3d985-20d4-486b-b28d-f22bec56220c"
      },
      "source": [
        "# build the best model and train it\n",
        "print(\"[INFO] training the best model...\")\n",
        "model = tuner.hypermodel.build(bestHP)\n",
        "H = model.fit(x=trainX, y=trainY,\n",
        "\tvalidation_data=(testX, testY), batch_size=config.BS,\n",
        "\tepochs=config.EPOCHS, callbacks=[es], verbose=1)\n",
        "\n",
        "# evaluate the network\n",
        "print(\"[INFO] evaluating network...\")\n",
        "predictions = model.predict(x=testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=labelNames))\n",
        "\n",
        "# generate the training loss/accuracy plot\n",
        "save_plot(H, args[\"plot\"])"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[INFO] training the best model...\n",
            "Epoch 1/50\n",
            "1875/1875 [==============================] - 11s 5ms/step - loss: 0.4226 - accuracy: 0.8544 - val_loss: 0.2987 - val_accuracy: 0.8898\n",
            "Epoch 2/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.2920 - accuracy: 0.8946 - val_loss: 0.2591 - val_accuracy: 0.9078\n",
            "Epoch 3/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2530 - accuracy: 0.9093 - val_loss: 0.2977 - val_accuracy: 0.8961\n",
            "Epoch 4/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2344 - accuracy: 0.9142 - val_loss: 0.2700 - val_accuracy: 0.9001\n",
            "Epoch 5/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.2141 - accuracy: 0.9212 - val_loss: 0.2450 - val_accuracy: 0.9134\n",
            "Epoch 6/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1955 - accuracy: 0.9290 - val_loss: 0.2321 - val_accuracy: 0.9183\n",
            "Epoch 7/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1780 - accuracy: 0.9350 - val_loss: 0.2626 - val_accuracy: 0.9164\n",
            "Epoch 8/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1652 - accuracy: 0.9401 - val_loss: 0.2229 - val_accuracy: 0.9236\n",
            "Epoch 9/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1514 - accuracy: 0.9445 - val_loss: 0.2184 - val_accuracy: 0.9270\n",
            "Epoch 10/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1349 - accuracy: 0.9506 - val_loss: 0.2611 - val_accuracy: 0.9138\n",
            "Epoch 11/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1257 - accuracy: 0.9540 - val_loss: 0.2385 - val_accuracy: 0.9246\n",
            "Epoch 12/50\n",
            "1875/1875 [==============================] - 9s 5ms/step - loss: 0.1213 - accuracy: 0.9554 - val_loss: 0.3229 - val_accuracy: 0.8979\n",
            "Epoch 13/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.1059 - accuracy: 0.9613 - val_loss: 0.2846 - val_accuracy: 0.9144\n",
            "Epoch 14/50\n",
            "1875/1875 [==============================] - 10s 5ms/step - loss: 0.0937 - accuracy: 0.9661 - val_loss: 0.2443 - val_accuracy: 0.9259\n",
            "[INFO] evaluating network...\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         top       0.91      0.86      0.88      1000\n",
            "     trouser       0.99      0.99      0.99      1000\n",
            "    pullover       0.89      0.89      0.89      1000\n",
            "       dress       0.93      0.92      0.93      1000\n",
            "        coat       0.86      0.91      0.88      1000\n",
            "      sandal       0.99      0.98      0.99      1000\n",
            "       shirt       0.78      0.80      0.79      1000\n",
            "     sneaker       0.95      0.98      0.97      1000\n",
            "         bag       0.99      0.98      0.99      1000\n",
            "  ankle boot       0.98      0.96      0.97      1000\n",
            "\n",
            "    accuracy                           0.93     10000\n",
            "   macro avg       0.93      0.93      0.93     10000\n",
            "weighted avg       0.93      0.93      0.93     10000\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ogkNauArL6u"
      },
      "source": [
        "For a detailed walkthrough of the concepts and code, be sure to refer to the full tutorial, [*Easy Hyperparameter Tuning with Keras Tuner and TensorFlow*](https://www.pyimagesearch.com/2021/06/07/easy-hyperparameter-tuning-with-keras-tuner-and-tensorflow/) published on 2021-06-07."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sef8alx4cGYc"
      },
      "source": [
        "# Code License Agreement\n",
        "```\n",
        "Copyright (c) 2021 PyImageSearch.com\n",
        "\n",
        "SIMPLE VERSION\n",
        "Feel free to use this code for your own projects, whether they are\n",
        "purely educational, for fun, or for profit. THE EXCEPTION BEING if\n",
        "you are developing a course, book, or other educational product.\n",
        "Under *NO CIRCUMSTANCE* may you use this code for your own paid\n",
        "educational or self-promotional ventures without written consent\n",
        "from Adrian Rosebrock and PyImageSearch.com.\n",
        "\n",
        "LONGER, FORMAL VERSION\n",
        "Permission is hereby granted, free of charge, to any person obtaining\n",
        "a copy of this software and associated documentation files\n",
        "(the \"Software\"), to deal in the Software without restriction,\n",
        "including without limitation the rights to use, copy, modify, merge,\n",
        "publish, distribute, sublicense, and/or sell copies of the Software,\n",
        "and to permit persons to whom the Software is furnished to do so,\n",
        "subject to the following conditions:\n",
        "The above copyright notice and this permission notice shall be\n",
        "included in all copies or substantial portions of the Software.\n",
        "Notwithstanding the foregoing, you may not use, copy, modify, merge,\n",
        "publish, distribute, sublicense, create a derivative work, and/or\n",
        "sell copies of the Software in any work that is designed, intended,\n",
        "or marketed for pedagogical or instructional purposes related to\n",
        "programming, coding, application development, or information\n",
        "technology. Permission for such use, copying, modification, and\n",
        "merger, publication, distribution, sub-licensing, creation of\n",
        "derivative works, or sale is expressly withheld.\n",
        "THE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND,\n",
        "EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES\n",
        "OF MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND\n",
        "NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS\n",
        "BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN\n",
        "ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN\n",
        "CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\n",
        "SOFTWARE.\n",
        "```"
      ]
    }
  ]
}